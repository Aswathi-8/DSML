{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38225f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "984a16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_valid,Y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7f1bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train .reshape(60000,784).astype('float32')\n",
    "X_valid =X_valid .reshape(10000,784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45cfa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /=255\n",
    "X_valid /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e58a643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbbc6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils as np_utils\n",
    "n_classes=10\n",
    "Y_train=keras.utils.np_utils.to_categorical(Y_train,n_classes)\n",
    "Y_valid=keras.utils.np_utils.to_categorical(Y_valid,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38d7fb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed386997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c52c5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3148c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1404bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e29f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1362de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:17:47.023694: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "469/469 [==============================] - 4s 3ms/step - loss: 0.0923 - accuracy: 0.1011\n",
      "Epoch 2/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.1081\n",
      "Epoch 3/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.1172\n",
      "Epoch 4/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.1294\n",
      "Epoch 5/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.1443\n",
      "Epoch 6/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.1603\n",
      "Epoch 7/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.1773\n",
      "Epoch 8/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.1982\n",
      "Epoch 9/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.2229\n",
      "Epoch 10/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.2497\n",
      "Epoch 11/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.2739\n",
      "Epoch 12/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.2962\n",
      "Epoch 13/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.3160\n",
      "Epoch 14/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.3393\n",
      "Epoch 15/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.3643\n",
      "Epoch 16/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0872 - accuracy: 0.3900\n",
      "Epoch 17/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.4124\n",
      "Epoch 18/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.4339\n",
      "Epoch 19/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.4501\n",
      "Epoch 20/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.4621\n",
      "Epoch 21/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.4727\n",
      "Epoch 22/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.4795\n",
      "Epoch 23/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0849 - accuracy: 0.4842\n",
      "Epoch 24/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.4866\n",
      "Epoch 25/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0842 - accuracy: 0.4873\n",
      "Epoch 26/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0839 - accuracy: 0.4891\n",
      "Epoch 27/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.4890\n",
      "Epoch 28/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.4910\n",
      "Epoch 29/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.4926\n",
      "Epoch 30/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.4956\n",
      "Epoch 31/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.4976\n",
      "Epoch 32/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.5001\n",
      "Epoch 33/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.5055\n",
      "Epoch 34/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0807 - accuracy: 0.5095\n",
      "Epoch 35/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.5147\n",
      "Epoch 36/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.5174\n",
      "Epoch 37/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.5226\n",
      "Epoch 38/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0789 - accuracy: 0.5304\n",
      "Epoch 39/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.5366\n",
      "Epoch 40/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0780 - accuracy: 0.5395\n",
      "Epoch 41/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.5468\n",
      "Epoch 42/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.5539\n",
      "Epoch 43/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.5603\n",
      "Epoch 44/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0760 - accuracy: 0.5674\n",
      "Epoch 45/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.5742\n",
      "Epoch 46/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.5800\n",
      "Epoch 47/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0746 - accuracy: 0.5855\n",
      "Epoch 48/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.5920\n",
      "Epoch 49/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.5980\n",
      "Epoch 50/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.6035\n",
      "Epoch 51/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.6097\n",
      "Epoch 52/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.6149\n",
      "Epoch 53/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.6204\n",
      "Epoch 54/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.6251\n",
      "Epoch 55/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0705 - accuracy: 0.6297\n",
      "Epoch 56/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0700 - accuracy: 0.6342\n",
      "Epoch 57/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0695 - accuracy: 0.6374\n",
      "Epoch 58/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0690 - accuracy: 0.6415\n",
      "Epoch 59/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0684 - accuracy: 0.6442\n",
      "Epoch 60/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0679 - accuracy: 0.6474\n",
      "Epoch 61/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.6504\n",
      "Epoch 62/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.6532\n",
      "Epoch 63/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.6562\n",
      "Epoch 64/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0659 - accuracy: 0.6585\n",
      "Epoch 65/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0653 - accuracy: 0.6609\n",
      "Epoch 66/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.6632\n",
      "Epoch 67/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0643 - accuracy: 0.6658\n",
      "Epoch 68/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0638 - accuracy: 0.6673\n",
      "Epoch 69/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.6699\n",
      "Epoch 70/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.6715\n",
      "Epoch 71/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0622 - accuracy: 0.6731\n",
      "Epoch 72/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0617 - accuracy: 0.6755\n",
      "Epoch 73/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0612 - accuracy: 0.6778\n",
      "Epoch 74/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0607 - accuracy: 0.6796\n",
      "Epoch 75/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0602 - accuracy: 0.6817\n",
      "Epoch 76/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0597 - accuracy: 0.6834\n",
      "Epoch 77/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.6854\n",
      "Epoch 78/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.6883\n",
      "Epoch 79/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.6891\n",
      "Epoch 80/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.6916\n",
      "Epoch 81/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.6943\n",
      "Epoch 82/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0568 - accuracy: 0.6963\n",
      "Epoch 83/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0563 - accuracy: 0.6981\n",
      "Epoch 84/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0558 - accuracy: 0.7005\n",
      "Epoch 85/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.7031\n",
      "Epoch 86/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0549 - accuracy: 0.7057\n",
      "Epoch 87/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0544 - accuracy: 0.7080\n",
      "Epoch 88/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0540 - accuracy: 0.7110\n",
      "Epoch 89/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0535 - accuracy: 0.7129\n",
      "Epoch 90/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0531 - accuracy: 0.7156\n",
      "Epoch 91/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0527 - accuracy: 0.7182\n",
      "Epoch 92/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.7212\n",
      "Epoch 93/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0518 - accuracy: 0.7236\n",
      "Epoch 94/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0514 - accuracy: 0.7258\n",
      "Epoch 95/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0510 - accuracy: 0.7279\n",
      "Epoch 96/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.7304\n",
      "Epoch 97/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0502 - accuracy: 0.7333\n",
      "Epoch 98/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.7358\n",
      "Epoch 99/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.7387\n",
      "Epoch 100/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0490 - accuracy: 0.7413\n",
      "Epoch 101/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0486 - accuracy: 0.7438\n",
      "Epoch 102/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0482 - accuracy: 0.7469\n",
      "Epoch 103/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0479 - accuracy: 0.7496\n",
      "Epoch 104/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0475 - accuracy: 0.7531\n",
      "Epoch 105/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0471 - accuracy: 0.7555\n",
      "Epoch 106/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0468 - accuracy: 0.7578\n",
      "Epoch 107/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0464 - accuracy: 0.7601\n",
      "Epoch 108/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0461 - accuracy: 0.7629\n",
      "Epoch 109/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0457 - accuracy: 0.7653\n",
      "Epoch 110/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0454 - accuracy: 0.7674\n",
      "Epoch 111/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0451 - accuracy: 0.7695\n",
      "Epoch 112/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0447 - accuracy: 0.7717\n",
      "Epoch 113/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.7739\n",
      "Epoch 114/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0441 - accuracy: 0.7762\n",
      "Epoch 115/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0438 - accuracy: 0.7789\n",
      "Epoch 116/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.7811\n",
      "Epoch 117/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0431 - accuracy: 0.7825\n",
      "Epoch 118/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0428 - accuracy: 0.7847\n",
      "Epoch 119/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.7868\n",
      "Epoch 120/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0422 - accuracy: 0.7888\n",
      "Epoch 121/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0420 - accuracy: 0.7911\n",
      "Epoch 122/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.7927\n",
      "Epoch 123/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0414 - accuracy: 0.7947\n",
      "Epoch 124/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0411 - accuracy: 0.7967\n",
      "Epoch 125/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.7985\n",
      "Epoch 126/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0406 - accuracy: 0.8002\n",
      "Epoch 127/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0403 - accuracy: 0.8023\n",
      "Epoch 128/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0400 - accuracy: 0.8039\n",
      "Epoch 129/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0398 - accuracy: 0.8057\n",
      "Epoch 130/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0395 - accuracy: 0.8068\n",
      "Epoch 131/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0393 - accuracy: 0.8086\n",
      "Epoch 132/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0390 - accuracy: 0.8106\n",
      "Epoch 133/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0388 - accuracy: 0.8120\n",
      "Epoch 134/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0385 - accuracy: 0.8131\n",
      "Epoch 135/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0383 - accuracy: 0.8147\n",
      "Epoch 136/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0380 - accuracy: 0.8159\n",
      "Epoch 137/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0378 - accuracy: 0.8174\n",
      "Epoch 138/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0376 - accuracy: 0.8188\n",
      "Epoch 139/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0374 - accuracy: 0.8199\n",
      "Epoch 140/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0371 - accuracy: 0.8209\n",
      "Epoch 141/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0369 - accuracy: 0.8224\n",
      "Epoch 142/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0367 - accuracy: 0.8236\n",
      "Epoch 143/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0365 - accuracy: 0.8248\n",
      "Epoch 144/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0363 - accuracy: 0.8258\n",
      "Epoch 145/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0360 - accuracy: 0.8269\n",
      "Epoch 146/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0358 - accuracy: 0.8282\n",
      "Epoch 147/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0356 - accuracy: 0.8289\n",
      "Epoch 148/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.8299\n",
      "Epoch 149/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.8306\n",
      "Epoch 150/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0350 - accuracy: 0.8315\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19bab38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = fetch_openml(data_id=1464, return_X_y=True)\n",
    "X_train, X_valid, Y_train,Y_valid = train_test_split(X, Y, stratify=Y)\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "654f65b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "Y_pred = clf.predict(X_valid)\n",
    "cm = confusion_matrix(Y_valid, Y_pred)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf3dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
